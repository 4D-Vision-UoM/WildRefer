{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5210432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from datasets.liferefer_dataset import LifeReferDataset\n",
    "from datasets.strefer_dataset import STReferDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa8dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# BEAUTY DETR\n",
    "# Copyright (c) 2022 Ayush Jain & Nikolaos Gkanatsios\n",
    "# Licensed under CC-BY-NC [see LICENSE for details]\n",
    "# All Rights Reserved\n",
    "# ------------------------------------------------------------------------\n",
    "# Parts adapted from Group-Free\n",
    "# Copyright (c) 2021 Ze Liu. All Rights Reserved.\n",
    "# Licensed under the MIT License.\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaModel, RobertaTokenizerFast\n",
    "\n",
    "from models.point_backbone_module import Pointnet2Backbone\n",
    "from models.image_backbone_module import VisualBackbone\n",
    "\n",
    "from models.modules import (\n",
    "    PointsObjClsModule, GeneralSamplingModule,\n",
    "    ClsAgnosticPredictHead, PositionEmbeddingLearned\n",
    ")\n",
    "from models.encoder_decoder_layers import (\n",
    "    BiEncoder, BiEncoderLayer, BiDecoderLayer, MultiCALayer, ImageMultiCALayer\n",
    ")\n",
    "\n",
    "\n",
    "class BeaUTyDETR(nn.Module):\n",
    "    \"\"\"\n",
    "    3D language grounder.\n",
    "\n",
    "    Args:\n",
    "        num_class (int): number of semantics classes to predict\n",
    "        num_obj_class (int): number of object classes\n",
    "        input_feature_dim (int): feat_dim of pointcloud (without xyz)\n",
    "        num_queries (int): Number of queries generated\n",
    "        num_decoder_layers (int): number of decoder layers\n",
    "        self_position_embedding (str or None): how to compute pos embeddings\n",
    "        contrastive_align_loss (bool): contrast queries and token features\n",
    "        d_model (int): dimension of features\n",
    "        fuse_img (bool): use detected box stream\n",
    "        pointnet_ckpt (str or None): path to pre-trained pp++ checkpoint\n",
    "        self_attend (bool): add self-attention in encoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args=None, num_class=50,\n",
    "                 input_feature_dim=3,\n",
    "                 num_queries=256,\n",
    "                 num_decoder_layers=6, self_position_embedding='loc_learned',\n",
    "                 contrastive_align_loss=True,\n",
    "                 d_model=288, pointnet_ckpt=None, resnet_ckpt=None,\n",
    "                 self_attend=True,\n",
    "                 frame_num=2,\n",
    "                 butd=False,\n",
    "                 ):\n",
    "        \"\"\"Initialize layers.\"\"\"\n",
    "        super().__init__()   \n",
    "        self.args = args     \n",
    "        self.num_queries = num_queries\n",
    "        self.num_decoder_layers = num_decoder_layers\n",
    "        self.self_position_embedding = self_position_embedding\n",
    "        self.contrastive_align_loss = contrastive_align_loss\n",
    "        self.butd = butd\n",
    "\n",
    "        # Visual encoder\n",
    "        self.point_backbone_net = Pointnet2Backbone(\n",
    "            input_feature_dim=input_feature_dim,\n",
    "            width=1\n",
    "        )\n",
    "        if input_feature_dim == 3 and pointnet_ckpt is not None:\n",
    "            self.point_backbone_net.load_state_dict(torch.load(\n",
    "                pointnet_ckpt\n",
    "            ), strict=False)\n",
    "            for p in self.point_backbone_net.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        self.image_backbone_net = VisualBackbone(d_model=d_model)\n",
    "        if resnet_ckpt is not None:\n",
    "            self.image_backbone_net.load_state_dict(torch.load(\n",
    "                resnet_ckpt\n",
    "            ), strict=False)\n",
    "            for p in self.image_backbone_net.parameters():\n",
    "                p.requires_grad = False\n",
    "        \n",
    "        # Box encoder\n",
    "        if self.butd:\n",
    "            self.box_embeddings = PositionEmbeddingLearned(6, 288)\n",
    "            \n",
    "        # MultiFrames Fusion\n",
    "        self.multi_fuser = nn.ModuleList()\n",
    "        self.multi_fuser_layers = 1\n",
    "        for _ in range(self.multi_fuser_layers):\n",
    "            self.multi_fuser.append(MultiCALayer(\n",
    "                d_model, n_heads=8, dim_feedforward=256,\n",
    "                dropout=0.1, activation=\"relu\",\n",
    "                frame_num=frame_num,\n",
    "            ))\n",
    "\n",
    "            \n",
    "        self.image_multi_fuser = nn.ModuleList()\n",
    "        for _ in range(self.multi_fuser_layers):\n",
    "            self.image_multi_fuser.append(ImageMultiCALayer(\n",
    "                d_model, n_heads=8, dim_feedforward=256,\n",
    "                dropout=0.1, activation=\"relu\",\n",
    "                frame_num=frame_num,\n",
    "            ))\n",
    "        \n",
    "        # Text Encoder\n",
    "        t_type = \"roberta-base\"\n",
    "        self.tokenizer = RobertaTokenizerFast.from_pretrained(t_type)\n",
    "        self.text_encoder = RobertaModel.from_pretrained(t_type)\n",
    "        for param in self.text_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.text_projector = nn.Sequential(\n",
    "            nn.Linear(self.text_encoder.config.hidden_size, d_model),\n",
    "            nn.LayerNorm(d_model, eps=1e-12),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "\n",
    "        # Cross-encoder (Text-Points)\n",
    "        self.pos_embed = PositionEmbeddingLearned(3, d_model)\n",
    "        bi_layer_pc = BiEncoderLayer(\n",
    "            d_model, dropout=0.1, activation=\"relu\",\n",
    "            n_heads=8, dim_feedforward=256,\n",
    "            self_attend_lang=self_attend, self_attend_vis=self_attend,\n",
    "            use_img_enc_attn=True,\n",
    "            use_butd_enc_attn=butd\n",
    "        )\n",
    "        self.cross_encoder_text_points = BiEncoder(bi_layer_pc, 3)\n",
    "\n",
    "        # Cross-encoder (Text-Image)\n",
    "        # bi_layer_img = BiEncoderLayer(\n",
    "        #     d_model, dropout=0.1, activation=\"relu\",\n",
    "        #     n_heads=8, dim_feedforward=256,\n",
    "        #     self_attend_lang=self_attend, self_attend_vis=self_attend,\n",
    "        #     use_img_enc_attn=False\n",
    "        # )\n",
    "        # self.cross_encoder_text_image = BiEncoder(bi_layer_img, 3)\n",
    "\n",
    "        # Query initialization\n",
    "        self.points_obj_cls = PointsObjClsModule(d_model)\n",
    "        self.gsample_module = GeneralSamplingModule()\n",
    "        self.decoder_query_proj = nn.Conv1d(d_model, d_model, kernel_size=1)\n",
    "\n",
    "        # Proposal (layer for size and center)\n",
    "        self.proposal_head = ClsAgnosticPredictHead(\n",
    "            num_class, 1, num_queries, d_model,\n",
    "            objectness=False, heading=False,\n",
    "            compute_sem_scores=True\n",
    "        )\n",
    "\n",
    "        # Transformer decoder layers\n",
    "        self.decoder = nn.ModuleList()\n",
    "        for _ in range(self.num_decoder_layers):\n",
    "            self.decoder.append(BiDecoderLayer(\n",
    "                d_model, n_heads=8, dim_feedforward=256,\n",
    "                dropout=0.1, activation=\"relu\",\n",
    "                self_position_embedding=self_position_embedding, butd=self.butd\n",
    "            ))\n",
    "\n",
    "        # Prediction heads\n",
    "        self.prediction_heads = nn.ModuleList()\n",
    "        for _ in range(self.num_decoder_layers):\n",
    "            self.prediction_heads.append(ClsAgnosticPredictHead(\n",
    "                num_class, 1, num_queries, d_model,\n",
    "                objectness=False, heading=False,\n",
    "                compute_sem_scores=True\n",
    "            ))\n",
    "\n",
    "        # Extra layers for contrastive losses\n",
    "        if contrastive_align_loss:\n",
    "            self.contrastive_align_projection_image = nn.Sequential(\n",
    "                nn.Linear(d_model, d_model),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(d_model, d_model),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(d_model, 64)\n",
    "            )\n",
    "            self.contrastive_align_projection_text = nn.Sequential(\n",
    "                nn.Linear(d_model, d_model),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(d_model, d_model),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(d_model, 64)\n",
    "            )\n",
    "\n",
    "        # Init\n",
    "        self.init_bn_momentum()\n",
    "\n",
    "    def _run_backbones(self, inputs, DEBUG=False):\n",
    "        \"\"\"Run visual and text backbones.\"\"\"\n",
    "        # Visual encoder\n",
    "        if DEBUG: \n",
    "            import pdb; pdb.set_trace()\n",
    "        point_clouds = inputs['point_clouds']\n",
    "\n",
    "        print(f\"[DEBUG - before doing anything] {point_clouds.shape}\")\n",
    "\n",
    "\n",
    "        B, K, N, C = point_clouds.shape\n",
    "        point_clouds = point_clouds.view(B*K, N, C)\n",
    "        if self.args.lr_backbone > 0:\n",
    "            end_points = self.point_backbone_net(point_clouds, end_points={})\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                end_points = self.point_backbone_net(point_clouds, end_points={})\n",
    "        if K == 1:\n",
    "            end_points['seed_inds'] = end_points['fp2_inds']\n",
    "            end_points['seed_xyz'] = end_points['fp2_xyz']\n",
    "            end_points['seed_features'] = end_points['fp2_features']\n",
    "        else:\n",
    "            seed_inds = end_points['fp2_inds'].view(B, K, -1)\n",
    "            seed_xyz = end_points['fp2_xyz'].view(B, K, -1, 3)\n",
    "            seed_features = end_points['fp2_features'].view(B, K, -1, seed_xyz.shape[2])\n",
    "            end_points['seed_inds'] = seed_inds[:, 0]\n",
    "            end_points['seed_xyz'] = seed_xyz[:, 0]\n",
    "            end_points['seed_features'] = seed_features[:, 0]\n",
    "            end_points['additional_seed_inds'] = seed_inds\n",
    "            end_points['additional_seed_xyz'] = seed_xyz\n",
    "            end_points['additional_seed_features'] = seed_features\n",
    "            end_points['fp2_inds'] = end_points['seed_inds']\n",
    "            end_points['fp2_xyz'] = end_points['seed_xyz']\n",
    "            end_points['fp2_features'] = end_points['seed_features']\n",
    "        \n",
    "\n",
    "        print(f\"[DEBUG - after running pointnet] {end_points['fp2_xyz'].shape}\")\n",
    "        import pdb; pdb.set_trace()\n",
    "        # Image encoder\n",
    "        image = inputs['image']\n",
    "        img_mask = inputs['img_mask']\n",
    "        B, K, H, W = img_mask.shape\n",
    "        image = image.view(B*K, -1, H, W)\n",
    "        img_mask = img_mask.view(B*K, H, W)\n",
    "        # end_points['image_feature']\n",
    "        # end_points['img_mask']\n",
    "        # end_points['img_pos']\n",
    "        if self.args.lr_backbone > 0:\n",
    "            end_points = self.image_backbone_net(image, img_mask, end_points=end_points)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                end_points = self.image_backbone_net(image, img_mask, end_points=end_points)\n",
    "        image_feature = end_points['image_feature'].view(B, K, end_points['image_feature'].shape[-2], end_points['image_feature'].shape[-1])\n",
    "        image_mask = ~end_points['img_mask'].view(B, K, end_points['image_feature'].shape[-1])\n",
    "        image_pos = end_points['img_pos'].view(B, K, end_points['img_pos'].shape[-2], end_points['img_pos'].shape[-1])\n",
    "        end_points['image_feature'] = image_feature[:, 0]\n",
    "        end_points['img_mask'] = image_mask[:, 0]\n",
    "        end_points['img_pos'] = image_pos[:, 0]\n",
    "        end_points['additional_image_feature'] = image_feature\n",
    "        end_points['additional_img_mask'] = image_mask\n",
    "        end_points['additional_img_pos'] = image_pos\n",
    "        \n",
    "        # Text encoder\n",
    "        tokenized = self.tokenizer.batch_encode_plus(\n",
    "            inputs['text'], padding=\"longest\", return_tensors=\"pt\"\n",
    "        ).to(point_clouds.device)\n",
    "        \n",
    "        encoded_text = self.text_encoder(**tokenized)\n",
    "        text_feats = self.text_projector(encoded_text.last_hidden_state)\n",
    "\n",
    "        # Invert attention mask that we get from huggingface\n",
    "        # because its the opposite in pytorch transformer\n",
    "        text_attention_mask = tokenized.attention_mask.ne(1).bool()\n",
    "        end_points['text_feats'] = text_feats\n",
    "        end_points['text_attention_mask'] = text_attention_mask\n",
    "        end_points['tokenized'] = tokenized\n",
    "        return end_points\n",
    "\n",
    "    def _generate_queries(self, xyz, features, end_points):\n",
    "        # kps sampling\n",
    "        points_obj_cls_logits = self.points_obj_cls(features)\n",
    "        end_points['seeds_obj_cls_logits'] = points_obj_cls_logits\n",
    "        sample_inds = torch.topk(\n",
    "            torch.sigmoid(points_obj_cls_logits).squeeze(1),\n",
    "            self.num_queries\n",
    "        )[1].int()\n",
    "        xyz, features, sample_inds = self.gsample_module(\n",
    "            xyz, features, sample_inds\n",
    "        )\n",
    "        end_points['query_points_xyz'] = xyz  # (B, V, 3)\n",
    "        end_points['query_points_feature'] = features  # (B, F, V)\n",
    "        end_points['query_points_sample_inds'] = sample_inds  # (B, V)\n",
    "        return end_points\n",
    "\n",
    "    def forward(self, inputs, DEBUG=True):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        Args:\n",
    "            inputs: dict\n",
    "                {point_clouds, text}\n",
    "                point_clouds (tensor): (B, Npoint, 3 + input_channels)\n",
    "                text (list): ['text0', 'text1', ...], len(text) = B\n",
    "\n",
    "                more keys if fuse_img is enabled:\n",
    "                    det_bbox_label_mask\n",
    "                    det_boxes\n",
    "                    det_class_ids\n",
    "        Returns:\n",
    "            end_points: dict\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        if DEBUG: \n",
    "            import pdb; pdb.set_trace()\n",
    "            print(\"[DEBUG] Forward pass\")\n",
    "        # Within-modality encoding\n",
    "        end_points = self._run_backbones(inputs, DEBUG)\n",
    "        \n",
    "        points_xyz = end_points['fp2_xyz']  # (B, points, 3)\n",
    "        points_features = end_points['fp2_features']  # (B, F, points)\n",
    "        points_mask = torch.zeros((len(points_xyz), points_xyz.size(1))).to(points_xyz.device).bool()  # (B, points)\n",
    "        original_text_feats = end_points['text_feats']  # (B, L, F)\n",
    "        text_padding_mask = end_points['text_attention_mask']  # (B, L)\n",
    "        \n",
    "        # Point Multi-Fuser\n",
    "        additional_points_xyz = end_points['additional_seed_xyz']\n",
    "        additional_points_features = end_points['additional_seed_features']\n",
    "        if DEBUG: \n",
    "            import pdb; pdb.set_trace()\n",
    "        for i in range(self.multi_fuser_layers):\n",
    "            points_features = self.multi_fuser[i](\n",
    "                query=points_features.transpose(1, 2).contiguous(),\n",
    "                key=additional_points_features.transpose(-1, -2).contiguous(),\n",
    "                value=additional_points_features.transpose(-1, -2).contiguous(),\n",
    "                query_pos=points_xyz,\n",
    "                key_pos=additional_points_xyz,\n",
    "                multi_mask=inputs['dynamic_mask']\n",
    "            )\n",
    "\n",
    "        # Image Multi-Fuser\n",
    "        image_features = end_points['image_feature']  # (B, F, N)\n",
    "        img_mask = end_points['img_mask']  # (B, N)\n",
    "        img_pos = end_points['img_pos']    # (B, F, N)\n",
    "        additional_image_feature = end_points['additional_image_feature']\n",
    "        additional_image_pos = end_points['additional_img_pos']\n",
    "        additional_img_mask = end_points['additional_img_mask']\n",
    "\n",
    "        for i in range(self.multi_fuser_layers):\n",
    "            image_features = self.image_multi_fuser[i](\n",
    "                query=image_features.transpose(1, 2).contiguous(),\n",
    "                key=additional_image_feature.transpose(-1, -2).contiguous(),\n",
    "                value=additional_image_feature.transpose(-1, -2).contiguous(),\n",
    "                query_pos=img_pos,\n",
    "                key_pos=additional_image_pos,\n",
    "                multi_mask=inputs['dynamic_mask'],\n",
    "                key_mask=additional_img_mask\n",
    "            )\n",
    "        image_features = image_features.transpose(1, 2).contiguous()\n",
    "\n",
    "\n",
    "        # Box encoding\n",
    "        if self.butd:\n",
    "            # attend on those features\n",
    "            detected_mask = ~inputs['det_bbox_label_mask']      # [111000] -> [000111]\n",
    "\n",
    "            if DEBUG: \n",
    "                import pdb; pdb.set_trace()\n",
    "            detected_feats =  self.box_embeddings(inputs['det_boxes']).transpose(1, 2).contiguous()\n",
    "        else:\n",
    "            detected_mask = None\n",
    "            detected_feats = None\n",
    "        \n",
    "        if DEBUG: \n",
    "            import pdb; pdb.set_trace()\n",
    "        # Cross-modality encoding (Text-Points)\n",
    "        points_features, text_feats = self.cross_encoder_text_points(\n",
    "            vis_feats=points_features.transpose(1, 2).contiguous(),\n",
    "            pos_feats=self.pos_embed(points_xyz).transpose(1, 2).contiguous(),\n",
    "            padding_mask=points_mask,\n",
    "            text_feats=original_text_feats,\n",
    "            text_padding_mask=text_padding_mask,\n",
    "            end_points=end_points,\n",
    "            enhanced_feats=image_features,\n",
    "            enhanced_mask=img_mask,\n",
    "            detected_feats=detected_feats,\n",
    "            detected_mask=detected_mask\n",
    "        )\n",
    "        \n",
    "        points_features = points_features.transpose(1, 2)\n",
    "        points_features = points_features.contiguous()  # (B, F, points)\n",
    "        end_points[\"text_memory\"] = text_feats\n",
    "        end_points['seed_features'] = points_features\n",
    "\n",
    "        if DEBUG: \n",
    "            import pdb; pdb.set_trace()\n",
    "        if self.contrastive_align_loss:\n",
    "            proj_tokens = F.normalize(\n",
    "                self.contrastive_align_projection_text(text_feats), p=2, dim=-1\n",
    "            )\n",
    "            end_points['proj_tokens'] = proj_tokens\n",
    "        \n",
    "        # Query Points Generation\n",
    "        end_points = self._generate_queries(\n",
    "            points_xyz, points_features, end_points\n",
    "        )\n",
    "        cluster_feature = end_points['query_points_feature']  # (B, F, V)\n",
    "        cluster_xyz = end_points['query_points_xyz']  # (B, V, 3)\n",
    "        query = self.decoder_query_proj(cluster_feature)\n",
    "        query = query.transpose(1, 2).contiguous()  # (B, V, F)\n",
    "\n",
    "        if self.contrastive_align_loss:\n",
    "            end_points['proposal_proj_queries'] = F.normalize(\n",
    "                self.contrastive_align_projection_image(query), p=2, dim=-1\n",
    "            )\n",
    "\n",
    "        if DEBUG: \n",
    "            import pdb; pdb.set_trace()\n",
    "        # Proposals (one for each query)\n",
    "        proposal_center, proposal_size = self.proposal_head(\n",
    "            cluster_feature,\n",
    "            base_xyz=cluster_xyz,\n",
    "            end_points=end_points,\n",
    "            prefix='proposal_'\n",
    "        )\n",
    "        base_xyz = proposal_center.detach().clone()  # (B, V, 3)\n",
    "        base_size = proposal_size.detach().clone()  # (B, V, 3)\n",
    "        query_mask = None\n",
    "\n",
    "        # Decoder\n",
    "        for i in range(self.num_decoder_layers):\n",
    "            prefix = 'last_' if i == self.num_decoder_layers-1 else f'{i}head_'\n",
    "\n",
    "            # Position Embedding for Self-Attention\n",
    "            if self.self_position_embedding == 'none':\n",
    "                query_pos = None\n",
    "            elif self.self_position_embedding == 'xyz_learned':\n",
    "                query_pos = base_xyz\n",
    "            elif self.self_position_embedding == 'loc_learned':\n",
    "                query_pos = torch.cat([base_xyz, base_size], -1)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            # Transformer Decoder Layer\n",
    "            query = self.decoder[i](\n",
    "                query, points_features.transpose(1, 2).contiguous(),\n",
    "                text_feats, query_pos,\n",
    "                query_mask,\n",
    "                text_padding_mask,\n",
    "                detected_feats=(\n",
    "                    detected_feats if self.butd\n",
    "                    else None\n",
    "                ),\n",
    "                detected_mask=detected_mask if self.butd else None\n",
    "            )  # (B, V, F)\n",
    "\n",
    "            if self.contrastive_align_loss:\n",
    "                end_points[f'{prefix}proj_queries'] = F.normalize(\n",
    "                    self.contrastive_align_projection_image(query), p=2, dim=-1\n",
    "                )\n",
    "\n",
    "            # Prediction\n",
    "            base_xyz, base_size = self.prediction_heads[i](\n",
    "                query.transpose(1, 2).contiguous(),  # (B, F, V)\n",
    "                base_xyz=cluster_xyz,\n",
    "                end_points=end_points,\n",
    "                prefix=prefix\n",
    "            )\n",
    "            base_xyz = base_xyz.detach().clone()\n",
    "            base_size = base_size.detach().clone()\n",
    "\n",
    "        return end_points\n",
    "\n",
    "    def init_bn_momentum(self):\n",
    "        \"\"\"Initialize batch-norm momentum.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
    "                m.momentum = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4024cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ca18c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avishka/anaconda3/envs/wildrefer_env/lib/python3.8/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset(args, split):\n",
    "    if args.dataset == 'liferefer':\n",
    "        return LifeReferDataset(args, split)\n",
    "    elif args.dataset == 'strefer':\n",
    "        return STReferDataset(args, split)\n",
    "    else:\n",
    "        raise ValueError(\"Wrong Dataset\")\n",
    "\n",
    "from models.bdetr import BeaUTyDETR\n",
    "# from .ap_helper import APCalculator, parse_predictions, parse_groundtruths\n",
    "from models.losses import HungarianMatcher, SetCriterion, compute_hungarian_loss\n",
    "\n",
    "def create_model(args):\n",
    "    return BeaUTyDETR(\n",
    "        args=args,\n",
    "        num_class=args.max_lang_num,\n",
    "        input_feature_dim=3,\n",
    "        num_queries=args.num_queries,\n",
    "        num_decoder_layers=args.num_decoder_layers,\n",
    "        self_position_embedding='loc_learned',\n",
    "        contrastive_align_loss=True,\n",
    "        d_model=288,\n",
    "        pointnet_ckpt=None,\n",
    "        resnet_ckpt=None,\n",
    "        self_attend=True,\n",
    "        frame_num=args.frame_num,\n",
    "        butd=args.butd\n",
    "    )\n",
    "\n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "def config():\n",
    "    return SimpleNamespace()\n",
    "\n",
    "args = config()\n",
    "args.batch_size = 32 \n",
    "args.butd = False \n",
    "args.dataset = 'liferefer'\n",
    "args.debug = False\n",
    "args.dynamic = True\n",
    "args.epochs = 100\n",
    "args.frame_num = 2\n",
    "args.img_size = 384\n",
    "args.lr = 0.0001\n",
    "args.lr_backbone = 0.001\n",
    "args.lr_step = [45, 80]\n",
    "args.max_lang_num = 100\n",
    "args.max_obj_num = 100\n",
    "args.num_decoder_layers = 6\n",
    "args.num_queries = 256\n",
    "args.num_workers = 8\n",
    "args.pretrain = 'weights/liferefer_weights.pth'\n",
    "args.seed = 42\n",
    "args.text_encoder_lr = 1e-05\n",
    "args.val_epoch = 1\n",
    "args.verbose_step = 10\n",
    "args.warmup_epoch = -1\n",
    "args.work_dir = 'outputs/debug'\n",
    "\n",
    "print(\"Create Dataset\")\n",
    "test_dataset = create_dataset(args, 'test')\n",
    "generator = torch.Generator()\n",
    "test_loader = DataLoader(test_dataset, args.batch_size, shuffle=False, num_workers=args.num_workers, generator=generator)\n",
    "\n",
    "print(\"Create Model\")\n",
    "model = create_model(args)\n",
    "\n",
    "# with open(\"Model_architecture.txt\", \"w\") as f:\n",
    "#     f.write(str(model))\n",
    "\n",
    "# import sys;exit()\n",
    "model.load_state_dict(torch.load(args.pretrain, map_location='cpu')['model'], strict=True)\n",
    "\n",
    "# model.cuda() \n",
    "model.to(\"cpu\")\n",
    "\n",
    "\n",
    "# Evaluate the model \n",
    "model.eval()\n",
    "loss = 0\n",
    "total_predict_boxes = []\n",
    "\n",
    "\n",
    "# test_loader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a523a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10730"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eaff47e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2571b36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/avishka/anaconda3/envs/wildrefer_env/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/avishka/anaconda3/envs/wildrefer_env/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/avishka/anaconda3/envs/wildrefer_env/lib/python3.8/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/avishka/anaconda3/envs/wildrefer_env/lib/python3.8/shutil.py\", line 722, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/home/avishka/anaconda3/envs/wildrefer_env/lib/python3.8/shutil.py\", line 720, in rmtree\n",
      "    os.rmdir(path)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-aio9jg3a'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "for batch in test_loader:\n",
    "    # print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c6f6f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5325e828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 30000, 6])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['point_clouds'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3433c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_test_sample = test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61e438d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 30000, 6)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]['point_clouds'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03e43b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point_clouds\n",
      "<class 'numpy.ndarray'>\n",
      "text\n",
      "<class 'str'>\n",
      "dynamic_mask\n",
      "<class 'numpy.ndarray'>\n",
      "image\n",
      "<class 'numpy.ndarray'>\n",
      "img_mask\n",
      "<class 'numpy.ndarray'>\n",
      "center_label\n",
      "<class 'numpy.ndarray'>\n",
      "size_gts\n",
      "<class 'numpy.ndarray'>\n",
      "box_label_mask\n",
      "<class 'numpy.ndarray'>\n",
      "point_instance_label\n",
      "<class 'numpy.ndarray'>\n",
      "sem_cls_label\n",
      "<class 'numpy.ndarray'>\n",
      "tokens_positive\n",
      "<class 'numpy.ndarray'>\n",
      "positive_map\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "input_data = one_test_sample\n",
    "for key in input_data:\n",
    "    print(key)\n",
    "    print(type(input_data[key]))\n",
    "    if isinstance(input_data[key], torch.Tensor):\n",
    "        print(\"before\", input_data[key].shape)\n",
    "        input_data[key] = input_data[key].unsqueeze(0).cuda()\n",
    "        print(\"after\", input_data[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab2aec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "351d4745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point_clouds\n",
      "text\n",
      "dynamic_mask\n",
      "image\n",
      "img_mask\n",
      "center_label\n",
      "size_gts\n",
      "box_label_mask\n",
      "point_instance_label\n",
      "sem_cls_label\n",
      "tokens_positive\n",
      "positive_map\n"
     ]
    }
   ],
   "source": [
    "one_test_sample_from_batch = dict()\n",
    "for key in batch:\n",
    "    print(key)\n",
    "    if isinstance(batch[key], torch.Tensor):\n",
    "        one_test_sample_from_batch[key] = batch[key][:1,].cuda()\n",
    "    else:\n",
    "        one_test_sample_from_batch[key] = batch[key][:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94dc1da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 30000, 6])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_test_sample_from_batch['point_clouds'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1fb563e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a girl wearing a dark gray jacket and carrying a pink school bag stands by the slide , and she turns her head to look at the slide . not mentioned']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_test_sample_from_batch['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "899ab217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'box_label_mask': tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0'),\n",
      " 'center_label': tensor([[[13.5800,  0.4178, -0.4951],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0'),\n",
      " 'dynamic_mask': tensor([[1, 1]], device='cuda:0'),\n",
      " 'image': tensor([[[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]]], device='cuda:0'),\n",
      " 'img_mask': tensor([[[[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "         [[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]]]], device='cuda:0'),\n",
      " 'point_clouds': tensor([[[[ 4.7206,  1.9876, -1.2644,  0.5020,  0.5020,  0.5020],\n",
      "          [ 6.0033, -2.3830, -1.2081,  0.7686,  0.7412,  0.7098],\n",
      "          [ 8.0429,  1.9055, -1.3000,  0.6353,  0.6314,  0.6157],\n",
      "          ...,\n",
      "          [ 8.8174, -4.7529, -1.2166,  0.3765,  0.3765,  0.3843],\n",
      "          [ 5.1618, -1.5494, -1.2014,  0.5608,  0.5608,  0.5608],\n",
      "          [ 3.5518,  2.1405, -1.2450,  0.4353,  0.4353,  0.4353]],\n",
      "\n",
      "         [[ 4.7059,  0.0833, -1.2163,  0.6824,  0.6824,  0.6824],\n",
      "          [ 5.9773,  1.5743, -1.2698,  0.6510,  0.6510,  0.6510],\n",
      "          [ 5.5216, -0.6344, -1.2037,  0.7216,  0.7176,  0.7098],\n",
      "          ...,\n",
      "          [22.3567, -9.4965,  0.7312,  0.3020,  0.3216,  0.2431],\n",
      "          [ 4.5195,  3.0972, -1.2875,  0.4039,  0.4039,  0.4039],\n",
      "          [18.3903, -4.4346, -0.9279,  0.5294,  0.4588,  0.4039]]]],\n",
      "       device='cuda:0'),\n",
      " 'point_instance_label': tensor([[-1, -1, -1,  ..., -1, -1, -1]], device='cuda:0'),\n",
      " 'positive_map': tensor([[[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'),\n",
      " 'sem_cls_label': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]], device='cuda:0'),\n",
      " 'size_gts': tensor([[[0.5986, 0.2228, 1.6844],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]]], device='cuda:0'),\n",
      " 'text': ['a girl wearing a dark gray jacket and carrying a pink school bag '\n",
      "          'stands by the slide , and she turns her head to look at the slide . '\n",
      "          'not mentioned'],\n",
      " 'tokens_positive': tensor([[[2, 6],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0]]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "pprint(one_test_sample_from_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf4a61e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['point_clouds', 'text', 'dynamic_mask', 'image', 'img_mask', 'center_label', 'size_gts', 'box_label_mask', 'point_instance_label', 'sem_cls_label', 'tokens_positive', 'positive_map'])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint \n",
    "\n",
    "pprint(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "03f603de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 30000, 6])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['point_clouds'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88b09c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a girl wearing a dark gray jacket and carrying a pink school bag stands by the slide , and she turns her head to look at the slide . not mentioned', \"a man is sitting and playing on a dinosaur rocker . the little boy does not look in the man's direction . not mentioned\", 'this is a sunny day . a girl wearing a white shirt is standing on the escalator .she also wears dark pants and black bag .at the same time , she turns around to look at the camera . not mentioned', 'in a bright room , a girl with long hair is writing on a board . she wears short sleeves and short pants . she is standing . not mentioned', 'this is a sunny day . a middle-aged man is standing and talking to a man standing next to him . he is watching the children who are playing . not mentioned', 'in a bright room , a man wearing shirt and mask is sitting on a chair . he is looking at a loptap . he is surrounded by a grounp of men . not mentioned', 'in a bright room , a girl with long pants is walking to the door . she is talking to the other girl next to her . not mentioned', 'this is a cloudy day . a boy wearing a bag is phoning . he is standing .his clothes is open . not mentioned', 'a man is walking with his girlfriend . he dawdled arm in arm with his girlfriend . he wears long sleeves and long pants . not mentioned', 'a girl takes her takeaway and walks to the left not mentioned', 'a girl wearing t-shirt , wide leg jeans and a handbag walking to a man not mentioned', 'this is a sunny day . a man wearing hoodie and short pants is playing basketball . he throws a ball and goes forward . not mentioned', 'a girl stands alone not mentioned', 'a girl bends over not mentioned', 'a man with a bag gives a box to a girl . not mentioned', 'a man wears striped sweater not mentioned', 'a man with glasses sits next to the man using a laptop not mentioned', 'a women in pink shows in the gif for only one frame not mentioned', 'a man with a mask and glassess is surrounded by many people not mentioned', 'the man is using a laptop not mentioned', 'a girl talks with two people in her right not mentioned', 'a boy with bag stands alone not mentioned', 'a boy stands next to a zebra with his girlfriend and he is looking at something and there are two people in front of him not mentioned', 'in front of the escalator , a slightly bald man in a plaid top , cargo trousers and sneakers who is walking forward with a backpack . not mentioned', 'the man with a mask raises his hand as he walking and is seemed to walk with a woman next to him . not mentioned', 'a man with glasses and a mask , wearing a short-sleeved polo shirt and sitting in a chair , is talking to the people around him .there is a girl standing next to him .there is a computer in front of him . not mentioned', 'he stares at the tablet in front of him , and then puts his hand in his hand and lies back on the chair and talks to people around him who looks like colleagues . not mentioned', 'a man wearing a mask coming out of the passage next to the escalator , holding his coat in his right hand . not mentioned', 'three men and two girls seem to be preparing for a meeting in the conference room . a man wearing a mask by the door raises a stool to his chest and walks across the table from the whiteboard . not mentioned', 'this black student is watching his laptop in the lab . not mentioned', 'this girl with grey jacket is walking and taking her food . not mentioned', 'this grey jacket girl is taking the escalator and her left hand is hanging on handrail not mentioned']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0a625e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4801679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avishka/sasika/WildRefer/models/position_encoding.py:37: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "with torch.inference_mode():\n",
    "    end_points = model(one_test_sample_from_batch, DEBUG=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "73401691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sa1_inds', 'sa1_xyz', 'sa1_features', 'sa2_inds', 'sa2_xyz', 'sa2_features', 'sa3_xyz', 'sa3_features', 'sa4_xyz', 'sa4_features', 'fp2_features', 'fp2_xyz', 'fp2_inds', 'seed_inds', 'seed_xyz', 'seed_features', 'additional_seed_inds', 'additional_seed_xyz', 'additional_seed_features', 'image_feature', 'img_mask', 'img_pos', 'additional_image_feature', 'additional_img_mask', 'additional_img_pos', 'text_feats', 'text_attention_mask', 'tokenized', 'text_memory', 'proj_tokens', 'seeds_obj_cls_logits', 'query_points_xyz', 'query_points_feature', 'query_points_sample_inds', 'proposal_proj_queries', 'proposal_base_xyz', 'proposal_center', 'proposal_pred_size', 'proposal_sem_cls_scores', '0head_proj_queries', '0head_base_xyz', '0head_center', '0head_pred_size', '0head_sem_cls_scores', '1head_proj_queries', '1head_base_xyz', '1head_center', '1head_pred_size', '1head_sem_cls_scores', '2head_proj_queries', '2head_base_xyz', '2head_center', '2head_pred_size', '2head_sem_cls_scores', '3head_proj_queries', '3head_base_xyz', '3head_center', '3head_pred_size', '3head_sem_cls_scores', '4head_proj_queries', '4head_base_xyz', '4head_center', '4head_pred_size', '4head_sem_cls_scores', 'last_proj_queries', 'last_base_xyz', 'last_center', 'last_pred_size', 'last_sem_cls_scores'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_points.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6289e80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens_positive', 'point_instance_label', 'text', 'image', 'point_clouds', 'size_gts', 'box_label_mask', 'sem_cls_label', 'dynamic_mask', 'positive_map', 'center_label'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the keys which are not in the end_points \n",
    "\n",
    "set(one_test_sample_from_batch.keys()) - set(end_points.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86df1289",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in one_test_sample_from_batch:\n",
    "        if key not in end_points:\n",
    "            end_points[key] = one_test_sample_from_batch[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b05a36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrast\n",
    "pred_center = end_points['last_center'].detach().cpu()\n",
    "pred_size = end_points[\"last_pred_size\"].detach().cpu()\n",
    "pred_boxes = torch.concat([pred_center, pred_size], dim=-1).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23fb7936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 6)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_boxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "94580296",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_tokens = end_points['proj_tokens']  # (B, tokens, 64)\n",
    "proj_queries = end_points['last_proj_queries']  # (B, Q, 64)\n",
    "sem_scores = torch.matmul(proj_queries, proj_tokens.transpose(-1, -2))\n",
    "sem_scores_ = sem_scores / 0.07  # (B, Q, tokens)\n",
    "sem_scores = torch.softmax(sem_scores_, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "61c9a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = end_points['tokenized']\n",
    "mask = token['attention_mask'].detach().cpu()\n",
    "last_pos = mask.sum(1) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba763ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeaUTyDETR(\n",
       "  (point_backbone_net): Pointnet2Backbone(\n",
       "    (sa1): PointnetSAModuleVotes(\n",
       "      (grouper): QueryAndGroup()\n",
       "      (mlp_module): SharedMLP(\n",
       "        (layer0): Conv2d(\n",
       "          (conv): Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (layer1): Conv2d(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (layer2): Conv2d(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (sa2): PointnetSAModuleVotes(\n",
       "      (grouper): QueryAndGroup()\n",
       "      (mlp_module): SharedMLP(\n",
       "        (layer0): Conv2d(\n",
       "          (conv): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (layer1): Conv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (layer2): Conv2d(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (sa3): PointnetSAModuleVotes(\n",
       "      (grouper): QueryAndGroup()\n",
       "      (mlp_module): SharedMLP(\n",
       "        (layer0): Conv2d(\n",
       "          (conv): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (layer1): Conv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (layer2): Conv2d(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (sa4): PointnetSAModuleVotes(\n",
       "      (grouper): QueryAndGroup()\n",
       "      (mlp_module): SharedMLP(\n",
       "        (layer0): Conv2d(\n",
       "          (conv): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (layer1): Conv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (layer2): Conv2d(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fp1): PointnetFPModule(\n",
       "      (mlp): SharedMLP(\n",
       "        (layer0): Conv2d(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (layer1): Conv2d(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fp2): PointnetFPModule(\n",
       "      (mlp): SharedMLP(\n",
       "        (layer0): Conv2d(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (layer1): Conv2d(\n",
       "          (conv): Conv2d(256, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(\n",
       "            (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (image_backbone_net): VisualBackbone(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "        )\n",
       "        (4): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "        )\n",
       "        (5): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (proj): Conv2d(512, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (position_embedding): PositionEmbeddingSine()\n",
       "  )\n",
       "  (multi_fuser): ModuleList(\n",
       "    (0): MultiCALayer(\n",
       "      (attn_modules): ModuleList(\n",
       "        (0): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "        )\n",
       "        (1): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm_modules): ModuleList(\n",
       "        (0): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dropout_modules): ModuleList(\n",
       "        (0): Dropout(p=0.1, inplace=False)\n",
       "        (1): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=288, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=288, bias=True)\n",
       "        (4): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (self_posembed): PositionEmbeddingLearned(\n",
       "        (position_embedding_head): Sequential(\n",
       "          (0): Conv1d(3, 288, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (image_multi_fuser): ModuleList(\n",
       "    (0): ImageMultiCALayer(\n",
       "      (attn_modules): ModuleList(\n",
       "        (0): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "        )\n",
       "        (1): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm_modules): ModuleList(\n",
       "        (0): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dropout_modules): ModuleList(\n",
       "        (0): Dropout(p=0.1, inplace=False)\n",
       "        (1): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=288, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=288, bias=True)\n",
       "        (4): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (text_encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (text_projector): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=288, bias=True)\n",
       "    (1): LayerNorm((288,), eps=1e-12, elementwise_affine=True)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (pos_embed): PositionEmbeddingLearned(\n",
       "    (position_embedding_head): Sequential(\n",
       "      (0): Conv1d(3, 288, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (cross_encoder_text_points): BiEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): BiEncoderLayer(\n",
       "        (self_attention_lang): TransformerEncoderLayerNoFFN(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (self_attention_visual): PosTransformerEncoderLayerNoFFN(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (cross_layer): CrossAttentionLayer(\n",
       "          (cross_lv): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (dropout_lv): Dropout(p=0.1, inplace=False)\n",
       "          (norm_lv): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (ffn_lv): Sequential(\n",
       "            (0): Linear(in_features=288, out_features=256, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=256, out_features=288, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (norm_lv2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_vl): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (dropout_vl): Dropout(p=0.1, inplace=False)\n",
       "          (norm_vl): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (ffn_vl): Sequential(\n",
       "            (0): Linear(in_features=288, out_features=256, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=256, out_features=288, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (norm_vl2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_d): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (dropout_d): Dropout(p=0.1, inplace=False)\n",
       "          (norm_d): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BiEncoderLayer(\n",
       "        (self_attention_lang): TransformerEncoderLayerNoFFN(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (self_attention_visual): PosTransformerEncoderLayerNoFFN(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (cross_layer): CrossAttentionLayer(\n",
       "          (cross_lv): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (dropout_lv): Dropout(p=0.1, inplace=False)\n",
       "          (norm_lv): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (ffn_lv): Sequential(\n",
       "            (0): Linear(in_features=288, out_features=256, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=256, out_features=288, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (norm_lv2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_vl): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (dropout_vl): Dropout(p=0.1, inplace=False)\n",
       "          (norm_vl): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (ffn_vl): Sequential(\n",
       "            (0): Linear(in_features=288, out_features=256, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=256, out_features=288, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (norm_vl2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_d): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (dropout_d): Dropout(p=0.1, inplace=False)\n",
       "          (norm_d): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): BiEncoderLayer(\n",
       "        (self_attention_lang): TransformerEncoderLayerNoFFN(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (self_attention_visual): PosTransformerEncoderLayerNoFFN(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (cross_layer): CrossAttentionLayer(\n",
       "          (cross_lv): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (dropout_lv): Dropout(p=0.1, inplace=False)\n",
       "          (norm_lv): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (ffn_lv): Sequential(\n",
       "            (0): Linear(in_features=288, out_features=256, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=256, out_features=288, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (norm_lv2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_vl): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (dropout_vl): Dropout(p=0.1, inplace=False)\n",
       "          (norm_vl): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (ffn_vl): Sequential(\n",
       "            (0): Linear(in_features=288, out_features=256, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=256, out_features=288, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (norm_vl2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_d): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (dropout_d): Dropout(p=0.1, inplace=False)\n",
       "          (norm_d): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (points_obj_cls): PointsObjClsModule(\n",
       "    (conv1): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "    (bn2): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv1d(288, 1, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (gsample_module): GeneralSamplingModule()\n",
       "  (decoder_query_proj): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "  (proposal_head): ClsAgnosticPredictHead(\n",
       "    (center_residual_head): ThreeLayerMLP(\n",
       "      (net): Sequential(\n",
       "        (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.3, inplace=False)\n",
       "        (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU()\n",
       "        (7): Dropout(p=0.3, inplace=False)\n",
       "        (8): Conv1d(288, 3, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (size_pred_head): ThreeLayerMLP(\n",
       "      (net): Sequential(\n",
       "        (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.3, inplace=False)\n",
       "        (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU()\n",
       "        (7): Dropout(p=0.3, inplace=False)\n",
       "        (8): Conv1d(288, 3, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (sem_cls_scores_head): ThreeLayerMLP(\n",
       "      (net): Sequential(\n",
       "        (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.3, inplace=False)\n",
       "        (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU()\n",
       "        (7): Dropout(p=0.3, inplace=False)\n",
       "        (8): Conv1d(288, 100, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ModuleList(\n",
       "    (0): BiDecoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (cross_l): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (dropout_l): Dropout(p=0.1, inplace=False)\n",
       "      (norm_l): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (cross_v): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (dropout_v): Dropout(p=0.1, inplace=False)\n",
       "      (norm_v): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=288, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=288, bias=True)\n",
       "        (4): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (self_posembed): PositionEmbeddingLearned(\n",
       "        (position_embedding_head): Sequential(\n",
       "          (0): Conv1d(6, 288, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BiDecoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (cross_l): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (dropout_l): Dropout(p=0.1, inplace=False)\n",
       "      (norm_l): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (cross_v): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (dropout_v): Dropout(p=0.1, inplace=False)\n",
       "      (norm_v): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=288, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=288, bias=True)\n",
       "        (4): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (self_posembed): PositionEmbeddingLearned(\n",
       "        (position_embedding_head): Sequential(\n",
       "          (0): Conv1d(6, 288, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): BiDecoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (cross_l): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (dropout_l): Dropout(p=0.1, inplace=False)\n",
       "      (norm_l): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (cross_v): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (dropout_v): Dropout(p=0.1, inplace=False)\n",
       "      (norm_v): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=288, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=288, bias=True)\n",
       "        (4): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (self_posembed): PositionEmbeddingLearned(\n",
       "        (position_embedding_head): Sequential(\n",
       "          (0): Conv1d(6, 288, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): BiDecoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (cross_l): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (dropout_l): Dropout(p=0.1, inplace=False)\n",
       "      (norm_l): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (cross_v): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (dropout_v): Dropout(p=0.1, inplace=False)\n",
       "      (norm_v): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=288, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=288, bias=True)\n",
       "        (4): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (self_posembed): PositionEmbeddingLearned(\n",
       "        (position_embedding_head): Sequential(\n",
       "          (0): Conv1d(6, 288, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): BiDecoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (cross_l): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (dropout_l): Dropout(p=0.1, inplace=False)\n",
       "      (norm_l): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (cross_v): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (dropout_v): Dropout(p=0.1, inplace=False)\n",
       "      (norm_v): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=288, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=288, bias=True)\n",
       "        (4): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (self_posembed): PositionEmbeddingLearned(\n",
       "        (position_embedding_head): Sequential(\n",
       "          (0): Conv1d(6, 288, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): BiDecoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (cross_l): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (dropout_l): Dropout(p=0.1, inplace=False)\n",
       "      (norm_l): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (cross_v): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (dropout_v): Dropout(p=0.1, inplace=False)\n",
       "      (norm_v): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=288, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=288, bias=True)\n",
       "        (4): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "      (self_posembed): PositionEmbeddingLearned(\n",
       "        (position_embedding_head): Sequential(\n",
       "          (0): Conv1d(6, 288, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(288, 288, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prediction_heads): ModuleList(\n",
       "    (0): ClsAgnosticPredictHead(\n",
       "      (center_residual_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 3, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "      (size_pred_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 3, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "      (sem_cls_scores_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 100, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ClsAgnosticPredictHead(\n",
       "      (center_residual_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 3, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "      (size_pred_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 3, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "      (sem_cls_scores_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 100, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ClsAgnosticPredictHead(\n",
       "      (center_residual_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 3, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "      (size_pred_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 3, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "      (sem_cls_scores_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 100, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ClsAgnosticPredictHead(\n",
       "      (center_residual_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 3, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "      (size_pred_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 3, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "      (sem_cls_scores_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 100, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): ClsAgnosticPredictHead(\n",
       "      (center_residual_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 3, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "      (size_pred_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 3, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "      (sem_cls_scores_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 100, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): ClsAgnosticPredictHead(\n",
       "      (center_residual_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 3, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "      (size_pred_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 3, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "      (sem_cls_scores_head): ThreeLayerMLP(\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.3, inplace=False)\n",
       "          (4): Conv1d(288, 288, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (5): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.3, inplace=False)\n",
       "          (8): Conv1d(288, 100, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (contrastive_align_projection_image): Sequential(\n",
       "    (0): Linear(in_features=288, out_features=288, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=288, out_features=288, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=288, out_features=64, bias=True)\n",
       "  )\n",
       "  (contrastive_align_projection_text): Sequential(\n",
       "    (0): Linear(in_features=288, out_features=288, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=288, out_features=288, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=288, out_features=64, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea2a45da",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = sem_scores.shape[0]\n",
    "pred_box = np.zeros((bs, 7))\n",
    "for i in range(bs):\n",
    "    sim = 1 - sem_scores[i, :, last_pos[i]]\n",
    "    max_idx = torch.argmax(sim)\n",
    "    box = pred_boxes[i, max_idx.item()]\n",
    "    pred_box[i, :6] = box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d6d344fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predict_boxes.append(pred_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6ac11627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 37117.73it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_boxes = np.vstack(total_predict_boxes)\n",
    "acc25, acc50, m_iou = test_dataset.evaluate(predict_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "acf4b793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wildrefer_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
