/home/avishka/anaconda3/envs/wildrefer_env/lib/python3.8/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Create Dataset
Create Model
  0%|[31m          [0m| 0/30 [00:00<?, ? data/s]/home/avishka/sasika/WildRefer/models/position_encoding.py:37: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
  3%|[31mâ–Ž         [0m| 1/30 [00:02<01:18,  2.70s/ data]  7%|[31mâ–‹         [0m| 2/30 [00:03<00:39,  1.40s/ data] 10%|[31mâ–ˆ         [0m| 3/30 [00:03<00:26,  1.02 data/s] 13%|[31mâ–ˆâ–Ž        [0m| 4/30 [00:04<00:19,  1.31 data/s] 17%|[31mâ–ˆâ–‹        [0m| 5/30 [00:04<00:16,  1.55 data/s] 20%|[31mâ–ˆâ–ˆ        [0m| 6/30 [00:04<00:13,  1.72 data/s] 23%|[31mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:05<00:12,  1.88 data/s] 27%|[31mâ–ˆâ–ˆâ–‹       [0m| 8/30 [00:05<00:10,  2.01 data/s] 30%|[31mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [00:06<00:10,  2.10 data/s] 33%|[31mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [00:06<00:09,  2.16 data/s] 37%|[31mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [00:07<00:08,  2.21 data/s] 40%|[31mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [00:07<00:07,  2.25 data/s] 43%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [00:07<00:07,  2.28 data/s] 47%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [00:08<00:06,  2.30 data/s] 50%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [00:08<00:06,  2.32 data/s] 53%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [00:09<00:06,  2.33 data/s] 57%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [00:09<00:05,  2.33 data/s] 60%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [00:10<00:05,  2.34 data/s] 63%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [00:10<00:04,  2.34 data/s] 67%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [00:10<00:04,  2.35 data/s] 70%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [00:11<00:03,  2.35 data/s] 73%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [00:11<00:03,  2.35 data/s] 77%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [00:12<00:02,  2.35 data/s] 80%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [00:12<00:02,  2.35 data/s] 83%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [00:13<00:02,  2.35 data/s] 87%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [00:13<00:01,  2.35 data/s] 90%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [00:13<00:01,  2.35 data/s] 93%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [00:14<00:00,  2.35 data/s] 97%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [00:14<00:00,  2.35 data/s]100%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [00:15<00:00,  2.64 data/s]100%|[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [00:15<00:00,  1.98 data/s]
  0%|          | 0/1066 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1066/1066 [00:00<00:00, 1019874.10it/s]
Acc25=0.6201 Acc50=0.5488 mIoU=0.3877
